<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>OVER THE FULLERENESHIFT</title>
  <subtitle>Personal website.</subtitle>
  <link href="http://shandriy.github.io/atom.xml" rel="self"/>
  <link href="http://shandriy.github.io"/>
  <updated>2025-3-19T00:00:00.000Z</updated>
  <author>
    <name>Shandriy</name>
  </author>
  <id>http://shandriy.github.io</id>
  <entry>
    <content></content>
    <title>Creating a Web Scraper - Thoughts on JavaScript and Why Archival is Necassary</title>
    <link href="https://shandriy.github.io/./notes/2025/3/19.htm"/>
    <id>./notes/2025/3/19.htm</id>
    <updated>2025-3-19T00:00:00.000Z</updated>
    <summary>   Note: Why a web scraper as opposed to a web crawler? Fundamentally, web
   scrapers and crawlers are the same thing - what makes the difference is
   more on whether it is malicious or not. For example, a web crawler
   might be crawling pages to power a search engine, while a web scraper
   might be trying to steal or rehost information from an entire website
   automatically. I'm choosing to say web scraper here since, as of
   writing, I have not implemented any support for the [1]robots.txt
   standard - more on that later....

References

   1. https://en.wikipedia.org/wiki/Robots.txt</summary>
  </entry>
</feed>